{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Intrusion Detection - MultiLabel DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and initialize findspark followed by importing pyspark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/usr/local/spark')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create SparkContext in the variable sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext(appName='networkIntrusionDecisionTreeMultiLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from numpy import array\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.mllib.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the input data file and create the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494021"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networkData = sc.textFile(\"kddcup.data_10_percent\")\n",
    "networkData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the total number of fields from line of the input data which is the comma separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "numfields = len(networkData.take(1)[0].split(\",\"))\n",
    "print(numfields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the distinct values of last field from the input lines.\n",
    "Create a dictionary assigning a number with the help of zipWithIndex, so the key will be the string from the last field and the value will be the unique number assigned to each string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = networkData.map(lambda line: (line.split(\",\")[numfields-1])).distinct()\n",
    "labels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multihop.\n",
      "rootkit.\n",
      "warezclient.\n",
      "ipsweep.\n",
      "teardrop.\n",
      "warezmaster.\n",
      "pod.\n",
      "perl.\n",
      "back.\n",
      "land.\n",
      "portsweep.\n",
      "guess_passwd.\n",
      "smurf.\n",
      "satan.\n",
      "imap.\n",
      "ftp_write.\n",
      "loadmodule.\n",
      "nmap.\n",
      "neptune.\n",
      "buffer_overflow.\n",
      "normal.\n",
      "spy.\n",
      "phf.\n"
     ]
    }
   ],
   "source": [
    "for x in labels.collect():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDict = dict(labels.zipWithIndex().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warezmaster. 5\n",
      "rootkit. 1\n",
      "ftp_write. 15\n",
      "guess_passwd. 11\n",
      "normal. 20\n",
      "ipsweep. 3\n",
      "teardrop. 4\n",
      "perl. 7\n",
      "nmap. 17\n",
      "smurf. 12\n",
      "loadmodule. 16\n",
      "phf. 22\n",
      "pod. 6\n",
      "spy. 21\n",
      "land. 9\n",
      "multihop. 0\n",
      "portsweep. 10\n",
      "satan. 13\n",
      "imap. 14\n",
      "neptune. 18\n",
      "back. 8\n",
      "warezclient. 2\n",
      "buffer_overflow. 19\n"
     ]
    }
   ],
   "source": [
    "for k, v in labelDict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to create a LabeledPoint from a comma delimited line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleanline(pstr):\n",
    "    line = pstr.split(\",\")\n",
    "    data = [line[0]]+line[4:numfields-1]\n",
    "    return LabeledPoint(labelDict[line[numfields-1]], array([float(x) for x in data]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run it as a lambda function on the input data. This will create an RDD in which each element is a LabeledPoint.\n",
    "And display the label and the features which is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandata=networkData.map(lambda line: get_cleanline(line))\n",
    "type(cleandata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.0,[0.0,181.0,5450.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,8.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,9.0,9.0,1.0,0.0,0.11,0.0,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,239.0,486.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,8.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,19.0,19.0,1.0,0.0,0.05,0.0,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,235.0,1337.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,8.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,29.0,29.0,1.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,219.0,1337.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,6.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,39.0,39.0,1.0,0.0,0.03,0.0,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,217.0,2032.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,6.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,49.0,49.0,1.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,217.0,2032.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,6.0,6.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,59.0,59.0,1.0,0.0,0.02,0.0,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,212.0,1940.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,2.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0,1.0,69.0,1.0,0.0,1.0,0.04,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,159.0,4087.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,5.0,5.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,11.0,79.0,1.0,0.0,0.09,0.04,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,210.0,151.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,8.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,8.0,89.0,1.0,0.0,0.12,0.04,0.0,0.0,0.0,0.0])\n",
      "(20.0,[0.0,212.0,786.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,8.0,8.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,8.0,99.0,1.0,0.0,0.12,0.05,0.0,0.0,0.0,0.0])\n"
     ]
    }
   ],
   "source": [
    "for line in cleandata.take(10):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandata.first().label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0, 181.0, 5450.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.0, 8.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 9.0, 9.0, 1.0, 0.0, 0.11, 0.0, 0.0, 0.0, 0.0, 0.0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandata.first().features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split this RDD into training and testing portions and cache them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = cleandata.randomSplit([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[16] at RDD at PythonRDD.scala:49"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.cache()\n",
    "testData.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a multi class label Decisiontree model with the training data. Used gini as the impurity parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree.trainClassifier(trainingData, numClasses=labels.count(), categoricalFeaturesInfo={}, impurity='gini', maxDepth=4, maxBins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model on test data using the predict method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testData.map(lambda x: x.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predicted values along with the the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n"
     ]
    }
   ],
   "source": [
    "for line in labelsAndPredictions.take(10):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the metrics from the predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MulticlassMetrics(labelsAndPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(7, 7, [110.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.0, 0.0, ..., 55.0, 10.0, 0.0, 2.0, 0.0, 0.0, 0.0, 9740.0], 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9913400552935436"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeModel classifier of depth 4 with 23 nodes\n",
      "  If (feature 20 <= 68.0)\n",
      "   If (feature 25 <= 0.48)\n",
      "    If (feature 31 <= 0.14)\n",
      "     If (feature 1 <= 0.0)\n",
      "      Predict: 18.0\n",
      "     Else (feature 1 > 0.0)\n",
      "      Predict: 20.0\n",
      "    Else (feature 31 > 0.14)\n",
      "     If (feature 1 <= 28.0)\n",
      "      Predict: 13.0\n",
      "     Else (feature 1 > 28.0)\n",
      "      Predict: 20.0\n",
      "   Else (feature 25 > 0.48)\n",
      "    If (feature 9 <= 0.0)\n",
      "     If (feature 33 <= 0.48)\n",
      "      Predict: 20.0\n",
      "     Else (feature 33 > 0.48)\n",
      "      Predict: 3.0\n",
      "    Else (feature 9 > 0.0)\n",
      "     If (feature 1 <= 1907.0)\n",
      "      Predict: 20.0\n",
      "     Else (feature 1 > 1907.0)\n",
      "      Predict: 8.0\n",
      "  Else (feature 20 > 68.0)\n",
      "   If (feature 1 <= 519.0)\n",
      "    If (feature 1 <= 28.0)\n",
      "     If (feature 1 <= 17.0)\n",
      "      Predict: 13.0\n",
      "     Else (feature 1 > 17.0)\n",
      "      Predict: 4.0\n",
      "    Else (feature 1 > 28.0)\n",
      "     Predict: 20.0\n",
      "   Else (feature 1 > 519.0)\n",
      "    Predict: 12.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Learned classification tree model:')\n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build another model this time with entropy as the impurity parameter. And perform the same tasks as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DecisionTree.trainClassifier(trainingData, numClasses=labels.count(), categoricalFeaturesInfo={}, impurity='entropy', maxDepth=4, maxBins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.predict(testData.map(lambda x: x.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsAndPredictions2 = testData.map(lambda lp: lp.label).zip(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n",
      "(20.0, 20.0)\n"
     ]
    }
   ],
   "source": [
    "for line in labelsAndPredictions2.take(10):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2 = MulticlassMetrics(labelsAndPredictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(6, 6, [42.0, 0.0, 0.0, 0.0, 0.0, 71.0, 0.0, 205.0, ..., 10678.0, 55.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9752.0], 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics2.confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9893681899495853"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics2.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model2:\n",
      "DecisionTreeModel classifier of depth 4 with 23 nodes\n",
      "  If (feature 20 <= 68.0)\n",
      "   If (feature 25 <= 0.48)\n",
      "    If (feature 31 <= 0.1)\n",
      "     If (feature 1 <= 0.0)\n",
      "      Predict: 18.0\n",
      "     Else (feature 1 > 0.0)\n",
      "      Predict: 20.0\n",
      "    Else (feature 31 > 0.1)\n",
      "     If (feature 1 <= 7.0)\n",
      "      Predict: 13.0\n",
      "     Else (feature 1 > 7.0)\n",
      "      Predict: 20.0\n",
      "   Else (feature 25 > 0.48)\n",
      "    If (feature 6 <= 0.0)\n",
      "     If (feature 1 <= 28.0)\n",
      "      Predict: 20.0\n",
      "     Else (feature 1 > 28.0)\n",
      "      Predict: 20.0\n",
      "    Else (feature 6 > 0.0)\n",
      "     If (feature 1 <= 1907.0)\n",
      "      Predict: 20.0\n",
      "     Else (feature 1 > 1907.0)\n",
      "      Predict: 8.0\n",
      "  Else (feature 20 > 68.0)\n",
      "   If (feature 1 <= 519.0)\n",
      "    If (feature 1 <= 28.0)\n",
      "     If (feature 1 <= 17.0)\n",
      "      Predict: 13.0\n",
      "     Else (feature 1 > 17.0)\n",
      "      Predict: 4.0\n",
      "    Else (feature 1 > 28.0)\n",
      "     Predict: 20.0\n",
      "   Else (feature 1 > 519.0)\n",
      "    Predict: 12.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Learned classification tree model2:')\n",
    "print(model2.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the model to predict for new set of data points.\n",
    "\n",
    "* Write functions to load a file, parse and classify new data using the predict method of the given model.\n",
    "* Create a new dict by reversing the key, values of label dictionary so that the names of the predicted values can be displayed instead of only the corresponding the number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currentline(pstr):\n",
    "    cline = pstr.split(\",\")\n",
    "    return [cline[0]]+cline[4:numfields-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(filename, pmodel):\n",
    "    currentData = sc.textFile(filename)\n",
    "    fields = currentData.map(lambda gline: get_currentline(gline))\n",
    "    return pmodel.predict(fields.map(lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDictRev = dict((v,k) for k, v in labelDict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate syntax to reverse key, values of a dictionary\n",
    "# labelDictRev2 = {v: k for k, v in labelDict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 multihop.\n",
      "1 rootkit.\n",
      "2 warezclient.\n",
      "3 ipsweep.\n",
      "4 teardrop.\n",
      "5 warezmaster.\n",
      "6 pod.\n",
      "7 perl.\n",
      "8 back.\n",
      "9 land.\n",
      "10 portsweep.\n",
      "11 guess_passwd.\n",
      "12 smurf.\n",
      "13 satan.\n",
      "14 imap.\n",
      "15 ftp_write.\n",
      "16 loadmodule.\n",
      "17 nmap.\n",
      "18 neptune.\n",
      "19 buffer_overflow.\n",
      "20 normal.\n",
      "21 spy.\n",
      "22 phf.\n"
     ]
    }
   ],
   "source": [
    "for k, v in labelDictRev.items():\n",
    "    print(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify new data given in current.txt file using the model with the help of above functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cLabelsAndPredictions = classify(\"current.txt\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 normal.\n",
      "20.0 normal.\n",
      "20.0 normal.\n",
      "18.0 neptune.\n",
      "20.0 normal.\n",
      "3.0 ipsweep.\n",
      "20.0 normal.\n",
      "18.0 neptune.\n",
      "20.0 normal.\n",
      "20.0 normal.\n"
     ]
    }
   ],
   "source": [
    "for pred in cLabelsAndPredictions.collect():\n",
    "    print(pred, labelDictRev[int(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass model2 also as the parameter to classify function and do the predictions if we find the accuracy of model2 to be better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
