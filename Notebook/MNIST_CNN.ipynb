{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " MNIST  CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfa9hdrZ3TJ-"
      },
      "source": [
        "MNIST (Modified National Institute of Standards and Technology) is a well-known dataset used in Computer Vision that was built by Yann Le Cun et. al. It is composed of images that are handwritten digits (0-9), split into a training set of 50,000 images and a test set of 10,000 where each image is of 28 x 28 pixels in width and height"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GczafuIMGymZ"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-qYluXbHKVc"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGFaEQlGHL15"
      },
      "source": [
        "(X_train,y_train), (X_test,y_test)= mnist.load_data()\n",
        "\n",
        "print(\"X train shape:  \", X_train.shape)\n",
        "print(\"y train shape:  \", y_train.shape)\n",
        "print(\"X test shape:  \", X_test.shape)\n",
        "print(\"y test shape:  \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXvlaCohIE3b"
      },
      "source": [
        "Before we train a CNN model, letâ€™s build a basic Fully Connected Neural Network for the dataset. The basic steps to build an image classification model using a neural network are:\n",
        "1.\tNormalize the image pixel values (divide by 255)\n",
        "3.\tOne-Hot Encode the categorical column\n",
        "4.\tBuild a model architecture (Sequential) with Dense layers\n",
        "5.\tTrain the model and make predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgAHJOVbIupP"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_06Q0t9XJ1q5"
      },
      "source": [
        ".\tNormalize the image pixel values (divide by 255)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKzgf4jEJ4LN"
      },
      "source": [
        "X_train=X_train/255\n",
        "X_test=X_test/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwSS_PP4KbYM"
      },
      "source": [
        "n_classes=10\n",
        "y_train = np_utils.to_categorical(y_train,n_classes)\n",
        "y_test = np_utils.to_categorical(y_test,n_classes)\n",
        "print(\"y train shape:  \", y_train.shape)\n",
        "print(\"y test shape:  \", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uD8OLe7LaCm"
      },
      "source": [
        "Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAimruc9LcIF"
      },
      "source": [
        "from keras.models import Sequential\n",
        "model= Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8MxTIgIxTo2"
      },
      "source": [
        "add convolution laer, maxpooling layer and the flattening  layer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3mV8TKTxRE8"
      },
      "source": [
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
        "model.add(Conv2D(25, kernel_size = (3,3), strides = (1,1), padding = 'valid', activation = 'relu' , input_shape = (28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "model.add(Flatten())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4U1_iQHM7N3"
      },
      "source": [
        "model.add(Dense(100, activation = 'relu'))\n",
        "model.add(Dense (10, activation = 'softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zu0x7spOyoT"
      },
      "source": [
        "model.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qtzi3C-PHlz",
        "outputId": "8c3d5151-b58d-4790-80c4-621e0395f844"
      },
      "source": [
        "model.fit(X_train,y_train, batch_size=128, epochs=10, validation_data= (X_test, y_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 40s 84ms/step - loss: 0.2029 - accuracy: 0.9419 - val_loss: 0.0714 - val_accuracy: 0.9775\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 39s 83ms/step - loss: 0.0592 - accuracy: 0.9822 - val_loss: 0.0562 - val_accuracy: 0.9832\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 38s 82ms/step - loss: 0.0358 - accuracy: 0.9890 - val_loss: 0.0513 - val_accuracy: 0.9835\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 38s 82ms/step - loss: 0.0222 - accuracy: 0.9934 - val_loss: 0.0569 - val_accuracy: 0.9818\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 39s 82ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0607 - val_accuracy: 0.9831\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 39s 82ms/step - loss: 0.0101 - accuracy: 0.9973 - val_loss: 0.0558 - val_accuracy: 0.9847\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 38s 81ms/step - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0723 - val_accuracy: 0.9810\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 38s 81ms/step - loss: 0.0050 - accuracy: 0.9987 - val_loss: 0.0804 - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 38s 81ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0563 - val_accuracy: 0.9854\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 38s 82ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0781 - val_accuracy: 0.9809\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a693c3c10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz8eJSia3PYL"
      },
      "source": [
        ""
      ]
    }
  ]
}